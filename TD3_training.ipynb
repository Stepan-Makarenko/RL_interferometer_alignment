{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_interf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal, Beta, Uniform\n",
    "from utils import Replay_buffer, action_rescale\n",
    "from TD3 import TD3\n",
    "from normal_noise import Normal_noise\n",
    "from Randomizations import make_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"interferobot\", group='Lense/TD3/Randomizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('interf-v1')\n",
    "randomizations=['Radius', 'Brightness', 'ChannelShifter','ActionNoise']\n",
    "env = make_env('interf-v2', randomizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_timesteps = 1e6     # max training episodes\n",
    "episode_timesteps = 50    # max timesteps in one episode\n",
    "log_interval = episode_timesteps * 20    # print avg reward in the interval\n",
    "evaluate_interval = log_interval * 10\n",
    "update_timestep = 10  # Replay buffer size, update policy every n timesteps\n",
    "replay_size = int(1e5)\n",
    "start_train = int(1e4)\n",
    "init_scheme = 'ortog_init'\n",
    "\n",
    "\n",
    "num_eval_episodes = 50\n",
    "log_dir= './logs'\n",
    "try:\n",
    "    os.makedirs(log_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# writer = SummaryWriter(log_dir)\n",
    "writer = wandb\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Agent hyperparameters\n",
    "agent_hyp = {\n",
    "    'writer': writer,\n",
    "     'state_dim': [16,64,64],\n",
    "     'action_dim': 5,\n",
    "     'n_latent_var': 512,\n",
    "     'pi_lr': 1e-5,\n",
    "     'q_lr': 1e-4,\n",
    "     'betas': (0.9, 0.999),\n",
    "     'gamma': 0.8,\n",
    "     'epochs': 10,\n",
    "     'batch_size': 32,\n",
    "     'device': device,\n",
    "     'polyak': 0.995,\n",
    "     'max_grad_norm': 10, # max size of optimization step\n",
    "     'target_noise': 0.2,\n",
    "     'noise_clip': 0.5,\n",
    "     'policy_delay': 1,\n",
    "     'critic_L2_norm': 0,\n",
    "     'encoder': 'VGG'\n",
    "    }\n",
    "\n",
    "decaying_hyp = {\n",
    "    'eps_max': 0.5,\n",
    "    'mult': 1 - 3e-6    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(visib):\n",
    "    eps = 1e-5\n",
    "    reward = (visib - np.log(1-visib + eps))\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize_obs_and_change_reward(gym.Wrapper):\n",
    "    \"\"\" Sets done flag to true when agent reach > 0.9 visib\"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        env.radius = 0.714\n",
    "        env.set_max_steps(episode_timesteps)\n",
    "        env.set_piezo_std(0.5) # It is a phase noise model. It was built right in the environment\n",
    "        self.evaluate = False\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Check is out of bound act\n",
    "        mirror_position = np.array([self.mirror1_screw_x, self.mirror1_screw_y,\n",
    "                                    self.mirror2_screw_x, self.mirror2_screw_y,\n",
    "                                    self.reduced_lens_dist])\n",
    "        new_mirror_position = mirror_position + action\n",
    "        out_bound = any(abs(new_mirror_position) > 1)\n",
    "        \n",
    "        obs, rew, done, info = self.env.step(action)\n",
    "        visib = rew + 1\n",
    "\n",
    "        rew = reward_func(env.info['visib_device'])\n",
    "        \n",
    "        if out_bound and not self.evaluate:\n",
    "            rew = -2 / episode_timesteps\n",
    "            done = True\n",
    "\n",
    "        normalized_obs = obs / 255          \n",
    "        return normalized_obs, rew, done, info\n",
    "\n",
    "    def reset(self, evaluate=False, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.evaluate = evaluate\n",
    "        normalized_obs = obs / 255\n",
    "        return normalized_obs\n",
    "\n",
    "\n",
    "env = Normalize_obs_and_change_reward(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TD3(**agent_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "if writer.__name__ == 'wandb':\n",
    "    logs_hyp = agent_hyp.copy()\n",
    "    del logs_hyp['device']\n",
    "    del logs_hyp['writer']\n",
    "    logs_hyp['max_timesteps'] = max_timesteps    # max training episodes\n",
    "    logs_hyp['episode_timesteps'] = episode_timesteps    # max timesteps in one episode\n",
    "    logs_hyp['update_timestep'] = update_timestep   # Replay buffer size, update policy every n timesteps\n",
    "    logs_hyp['replay_size'] = replay_size\n",
    "    logs_hyp['start_train'] = start_train\n",
    "    logs_hyp['init_scheme'] = init_scheme\n",
    "    logs_hyp['randomizations'] = randomizations\n",
    "    logs_hyp.update(decaying_hyp)\n",
    "    if type(logs_hyp['target_noise']) == type(lambda: x):\n",
    "        logs_hyp['target_noise'] = logs_hyp['target_noise'].__name__\n",
    "        logs_hyp.update(decaying_td_noise)\n",
    "    \n",
    "    writer.config.update(logs_hyp)\n",
    "    \n",
    "    def add_scalar(self, name, value, timestep):\n",
    "        return self.log({name: value}, timestep)\n",
    "\n",
    "    def add_histogram(self, name, value, timestep):\n",
    "        return self.log({name: wandb.Histogram(value.detach().cpu().numpy())}, timestep)\n",
    "    def add_figure(self, name, fig, timestep):\n",
    "        return self.log({name: wandb.Image(fig)}, timestep)\n",
    "\n",
    "    writer.add_scalar = types.MethodType(add_scalar, writer)\n",
    "    writer.add_histogram = types.MethodType(add_histogram, writer)\n",
    "    writer.add_figure = types.MethodType(add_figure, writer)\n",
    "    writer.watch(agent.policy_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(agent, timestep):\n",
    "    agent.eval()\n",
    "    average_episode_reward = np.zeros((num_eval_episodes, episode_timesteps))\n",
    "    all_visib = np.zeros((num_eval_episodes, episode_timesteps))\n",
    "    episode_mirror1 = []\n",
    "    episode_mirror2 = []\n",
    "    episode_angle_between_beams = []\n",
    "    all_out_bound = []\n",
    "    for episode in range(num_eval_episodes):\n",
    "        obs = env.reset(evaluate=True)\n",
    "        episode_mirror1.append([env.mirror1_screw_x, env.mirror1_screw_y])\n",
    "        episode_mirror2.append([env.mirror2_screw_x, env.mirror2_screw_y])\n",
    "        done = False\n",
    "        episode_reward = []\n",
    "        episode_visib = []\n",
    "        j = -1\n",
    "        while not done:\n",
    "            j += 1\n",
    "            with torch.no_grad():\n",
    "                mu = agent(np.array([obs]))\n",
    "                action = mu.detach().cpu().numpy()[0]\n",
    "                res_act = action_rescale(action)\n",
    "            \n",
    "            obs, reward, done, info = env.step(res_act)\n",
    "            average_episode_reward[episode, j] += reward\n",
    "            all_visib[episode, j] += info['visib_device']\n",
    "\n",
    "    writer.add_scalar('eval/episode_reward',\n",
    "                      np.array(average_episode_reward).sum(axis=1).mean(),\n",
    "                      timestep\n",
    "    )\n",
    "    writer.add_scalar('eval/Mean visib',\n",
    "                          np.array(all_visib).mean(),\n",
    "                          timestep\n",
    "    )\n",
    "    writer.add_scalar('eval/median_episode_reward',\n",
    "                      np.median(np.array(average_episode_reward).sum(axis=1)),\n",
    "                      timestep\n",
    "    )\n",
    "    writer.add_scalar('eval/min_episode_reward',\n",
    "                      np.min(np.array(average_episode_reward).sum(axis=1)),\n",
    "                      timestep\n",
    "    )\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    all_visib = np.array(all_visib)\n",
    "    all_std = np.sqrt(((all_visib - all_visib.mean(axis=0)) ** 2).mean(0))\n",
    "    upper_bound = (np.array(all_visib).mean(axis=0) + all_std)\n",
    "    lower_bound = np.clip((np.array(all_visib).mean(axis=0) - all_std), a_min=0, a_max=None)\n",
    "    plt.plot(all_visib.mean(axis=0))\n",
    "    plt.fill_between(np.arange(all_visib.shape[1]), upper_bound, lower_bound, facecolor='blue', alpha=0.2)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "\n",
    "    plt.grid(which='major',\n",
    "            color = 'k', \n",
    "            linewidth = 1)\n",
    "\n",
    "    plt.grid(which='minor', \n",
    "            color = 'k', \n",
    "            linestyle = ':')\n",
    "    plt.ylim(0,1)  \n",
    "  \n",
    "    writer.add_figure('eval/Visib_distrib', fig, timestep)\n",
    "    return np.array(average_episode_reward).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Replay_buffer(replay_size, agent_hyp['state_dim'], agent_hyp['action_dim'])\n",
    "\n",
    "warm_up_step = 0\n",
    "while warm_up_step < start_train:\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        action = np.random.uniform(-1, 1, agent_hyp['action_dim'])\n",
    "        resc_act = action_rescale(action)\n",
    "        next_state, rewards, dones, info = env.step(resc_act)\n",
    "        \n",
    "        memory.add(state, action, rewards, dones)\n",
    "        state = next_state\n",
    "        \n",
    "        warm_up_step += 1\n",
    "        if dones:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 34003 \t episode reward: 0.7516315028328091 \t\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(device)\n",
    "\n",
    "best_reward = 0\n",
    "epoch_reward_history = []\n",
    "\n",
    "timestep = 0\n",
    "noise = Normal_noise(agent_hyp['action_dim'], scale=exp_decay_eps(timestep))\n",
    "eval_triger = 0\n",
    "log_triger = 0\n",
    "\n",
    "# training loop\n",
    "episode_rewards = []\n",
    "episode_visib = []\n",
    "episode_max_visib = []\n",
    "episode_angle_between_beams = []\n",
    "episode_step = 0\n",
    "state = env.reset()\n",
    "while timestep < max_timesteps:\n",
    "    episode_rewards.append(0)\n",
    "    episode_max_visib.append(0)\n",
    "    episode_angle_between_beams = []\n",
    "    noise.reset()\n",
    "    eps = exp_decay_eps(timestep)\n",
    "    noise.scale = eps\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        timestep += 1\n",
    "        episode_step += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action = agent.select_action(np.array([state]), noise)\n",
    "            resc_act = action_rescale(action)\n",
    "        \n",
    "        next_state, rewards, dones, info = env.step(resc_act)\n",
    "                  \n",
    "        \n",
    "        # Saving reward and is_terminal:\n",
    "        memory.add(state, action, rewards, dones)\n",
    "        state = next_state\n",
    "        \n",
    "        # update if its time\n",
    "        if timestep % update_timestep == 0:\n",
    "            agent.update(memory, timestep, False)\n",
    "\n",
    "        episode_rewards[-1] += rewards \n",
    "        episode_visib.append(info['visib_device'])\n",
    "        episode_max_visib[-1] = env.info['visib_device'] if env.info['visib_device'] > episode_max_visib[-1] else episode_max_visib[-1]\n",
    "        episode_angle_between_beams.append(info['angle_between_beams'])\n",
    "        \n",
    "        if dones:\n",
    "            break\n",
    "    \n",
    "    # Evaluating\n",
    "    if timestep // evaluate_interval > eval_triger:\n",
    "        eval_triger += 1\n",
    "        eval_reward = evaluate(agent.policy_old, timestep)\n",
    "\n",
    "        if eval_reward > best_reward:\n",
    "            best_reward = eval_reward\n",
    "            torch.save({\n",
    "                'actor': agent.policy_old.state_dict(),\n",
    "                'explorer': agent.policy.state_dict(),\n",
    "                'Q1': agent.critic1.state_dict(),\n",
    "                'Q2': agent.critic2.state_dict(),\n",
    "                'tg_Q1': agent.target_critic1.state_dict(),\n",
    "                'tg_Q2': agent.target_critic2.state_dict(),\n",
    "            }, log_dir+'/agent{:.3f}.pt'.format(eval_reward))\n",
    "            if writer.__name__ == 'wandb':\n",
    "                wandb.save(log_dir+'/agent{:.3f}.pt'.format(eval_reward))\n",
    "\n",
    "\n",
    "    # logging\n",
    "    if timestep // log_interval > log_triger:\n",
    "        log_triger += 1\n",
    "        writer.add_scalar('Hyperparameters/Eps',\n",
    "                          eps,\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Mean_reward_per_trajectory',\n",
    "                          np.mean(episode_rewards),\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Median_reward_per_trajectory',\n",
    "                          np.median(episode_rewards),\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Max_reward_per_trajectory',\n",
    "                          np.max(episode_rewards),\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Min_reward_per_trajectory',\n",
    "                          np.min(episode_rewards),\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Mean_episode_length',\n",
    "                          episode_step / len(episode_rewards),\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Mean visib',\n",
    "                          np.array(episode_visib).mean(),\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Angle between beams',\n",
    "                          np.array(episode_angle_between_beams).mean(),\n",
    "                          timestep\n",
    "        )\n",
    "        writer.add_scalar('Effectiveness/Max visib',\n",
    "                          np.array(episode_max_visib).mean(),\n",
    "                          timestep\n",
    "        )\n",
    "        clear_output(True)\n",
    "        print('Timestep {} \\t episode reward: {} \\t'.format(timestep, np.mean(episode_rewards)))\n",
    "        epoch_reward_history.append(np.mean(episode_rewards))\n",
    "        plt.title(\"Reward per episod\")\n",
    "        plt.plot(epoch_reward_history)\n",
    "        plt.show()  \n",
    "        \n",
    "        episode_rewards = []\n",
    "        episode_step = 0\n",
    "        episode_visib = []\n",
    "        episode_max_visib = []\n",
    "        episode_angle_between_beams = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}